# -*- coding: utf-8 -*-
"""Copy of ROCK_MAIN_FILE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CP1-AxQpgQmlO6O4kSXBl57ENeGHCxU7
"""

!pip install -q kaggle

!pip install python-telegram-bot
from telegram.ext import *
from io import BytesIO
import cv2
import numpy as np
import tensorflow as tf
from datetime import datetime
from pytz import timezone

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!mkdir -p rock_classificaton/data
# %cd rock_classificaton
!mkdir -p data/0_raw data/1_extracted data/2_processed data/3_consume

raw_data_dir = 'data/0_raw/'
extracted_data_dir = 'data/1_extracted/'
processed_data_dir = 'data/2_processed/'
extracted_dataset_dir = extracted_data_dir + "Rock_Dataset/"

zip_file_name = "igneous-metamorphic-sedimentary-rocks-and-minerals.zip"

!kaggle datasets download mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals --path $raw_data_dir
!unzip $raw_data_dir$zip_file_name -d $extracted_data_dir

import os
import shutil

classes = os.listdir(extracted_data_dir+"/Rock_Dataset/")
classes

import os
import shutil

# modified below code to reduce redundancy and improve reusability
for c in classes:
    target = f"data/2_processed/{c}"
    os.makedirs(target, exist_ok=True)
    source = f"data/1_extracted/Rock_Dataset/{c}" 
    for root, sub, files in os.walk(source):
        for file_name in files:
            path = os.path.join(root, file_name)
            shutil.move(path, target)

for c in classes:
    path = f"data/2_processed/{c}"
    i=0
    for file_name in os.listdir(path):
        full_file_path = os.path.join(path, file_name)
        new_name = os.path.join(path, f"{c}_{i}.jpg")
        os.rename(full_file_path, new_name)
        i=i+1

import os
import cv2
import imghdr

def check_images( s_dir, ext_list):
    bad_images=[]
    bad_ext=[]
    s_list= os.listdir(s_dir)
    for klass in s_list:
        klass_path=os.path.join (s_dir, klass)
        print ('processing class directory ', klass)
        if os.path.isdir(klass_path):
            file_list=os.listdir(klass_path)
            for f in file_list:               
                f_path=os.path.join (klass_path,f)
                tip = imghdr.what(f_path)
                if ext_list.count(tip) == 0:
                  bad_images.append(f_path)
                if os.path.isfile(f_path):
                    try:
                        img=cv2.imread(f_path)
                        shape=img.shape
                    except:
                        print('file ', f_path, ' is not a valid image file')
                        bad_images.append(f_path)
                else:
                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)
        else:
            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')
    return bad_images, bad_ext

source_dir =r'/content/rock_classificaton/data/2_processed'
good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions
bad_file_list, bad_ext_list=check_images(source_dir, good_exts)
if len(bad_file_list) !=0:
    print('improper image files are listed below')
    for i in range (len(bad_file_list)):
        print (bad_file_list[i])
else:
    print(' no improper image files were found')

for i in bad_file_list:
    os.remove(i)
    print("% s has been removed successfully" % i)

import matplotlib.pyplot as plt
import numpy as np
# from skimage.io import imread
# from skimage.transform import resize

target = []
images = []
flat_data=[]
data_dir='data/2_processed'
CATEGORIES=['igneous rocks','metamorphic rocks','minerals','sedimentary rocks']

CATEGORIES

class_paths = []

for class_var, category in enumerate(CATEGORIES):
#   class_var=CATEGORIES.index(category)
#   print(class_var)
  path = os.path.join(data_dir, category)
  class_paths.append(path)

class_paths

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/rock_classificaton/

image_paths = []
image_classes = []
for path in class_paths:
    image_paths.extend(list(map(lambda x: os.path.join(path, x), os.listdir(path))))
print(image_paths)

import pandas as pd
image_data = pd.DataFrame({"image_paths":image_paths})
image_data['classes'] = image_data['image_paths'].apply(lambda x: x.split('/')[-2])

image_data

img_height, img_width = (200,200)
batch_size = 10
#batch_size=32 and image width = 150 150

!rm -rf /content/rock_classificaton/data/2_processed/.ipynb_checkpoints

import tensorflow as tf

train_ds = tf.keras.utils.image_dataset_from_directory(
  "/content/rock_classificaton/data/2_processed",
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=10)

val_ds = tf.keras.utils.image_dataset_from_directory(
  "/content/rock_classificaton/data/2_processed",
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

set(map(lambda x:x.split('.')[-1], train_ds.file_paths))

set(map(lambda x:x.split('.')[-1], val_ds.file_paths))

class_names = train_ds.class_names
print(class_names)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

#chatbot code
TOKEN = '5240965914:AAFEit9NaJmbigcyvPV_vJ4Ke4ihBCVqK6M'

normalization_layer = tf.keras.layers.Rescaling(1./255)

import numpy as np

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

num_classes = 4
"""
model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255),
  tf.keras.layers.Conv2D(32,3,padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
   tf.keras.layers.Conv2D(32,3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
   tf.keras.layers.Conv2D(32,3,padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(4, activation='softmax'),
  tf.keras.layers.Dense(num_classes)
  
])"""
model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(16, kernel_size = (3,3), input_shape = (200,200,3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
          
        tf.keras.layers.Conv2D(32, kernel_size = (3,3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.MaxPooling2D(5,5),
        
        tf.keras.layers.Conv2D(64, kernel_size = (3,3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        
        tf.keras.layers.Conv2D(128, kernel_size = (3,3)),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        tf.keras.layers.MaxPooling2D(5,5),

        tf.keras.layers.Flatten(),
    
        tf.keras.layers.Dense(64),
        tf.keras.layers.Dropout(rate = 0.2),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
        
        tf.keras.layers.Dense(32),
        tf.keras.layers.Dropout(rate = 0.2),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(),
    
        tf.keras.layers.Dense(16),
        tf.keras.layers.Dropout(rate = 0.2),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.LeakyReLU(1),
    
        tf.keras.layers.Dense(4, activation = 'softmax'),
        tf.keras.layers.Dense(num_classes)    
        ])

#chatbot code
def start(update, context):
    update.message.reply_text("Welcome!")

#chatbot code
def help(update, context):
    update.message.reply_text(""" 
    /start - Starts conversation 
    /help - Shows this message 
    /train - Trains neural networks 
    """)

#chatbot code
def train(update, context):
    update.message.reply_text("Model is being trained...")
    model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    model.fit(train_ds,validation_data=val_ds,epochs=50,batch_size=10)
    timestr=datetime.now()
    timestr1=timestr.astimezone(timezone('Asia/Kolkata'))
    timestr1=str(timestr1)
    model.save("/BTECH PROJECT/Accuracy/classifier_"+timestr1+".h5")
    update.message.reply_text("Done! You can now send a photo!")

#chatbot code
def handle_message(update, context):
    update.message.reply_text("Please train the model and send a picture!")

#chatbot code
def handle_photo(update, context):
    file = context.bot.get_file(update.message.photo[-1].file_id)
    f = BytesIO(file.download_as_bytearray())
    file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    img = cv2.resize(img, (200,200), interpolation=cv2.INTER_AREA)
    #prediction=model.predict(img)[0]
    #print(prediction)
    prediction = model.predict(np.array([img / 255]))
    update.message.reply_text(f"In this image I see a {class_names[np.argmax(prediction)]}")

#chatbot code
updater = Updater(TOKEN, use_context=True)
dp = updater.dispatcher
dp.add_handler(CommandHandler("start", start))
dp.add_handler(CommandHandler("help", help))
dp.add_handler(CommandHandler("train", train))
dp.add_handler(MessageHandler(Filters.text, handle_message))
dp.add_handler(MessageHandler(Filters.photo, handle_photo))

#chatbot code
updater.start_polling()
updater.idle()

from keras.models import load_model
loaded_model = load_model('/BTECH PROJECT/Accuracy/classifier_2022-05-26 00:26:27.439409+05:30.h5')

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=5,
  batch_size=32
)

print("Acurracy:", loaded_model.evaluate(val_ds, verbose=2))

def predict_image(img):
  img_4d=img.reshape(-1,200,200,3)
  prediction=loaded_model.predict(img_4d)[0]
  print(prediction)
  #return {class_names[i]: float(prediction[i]) for i in range(4) if prediction[i] > 0}
  return {class_names[i]: float(prediction[i]) for i in range(4)}

!pip install gradio
import gradio as gr

image = gr.inputs.Image(shape=(200,200))
label = gr.outputs.Label(num_top_classes=4  )

gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')